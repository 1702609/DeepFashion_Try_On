{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from util.image_pool import ImagePool\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from .base_model import BaseModel\n",
    "from . import networks\n",
    "import torch.nn.functional as F\n",
    "NC=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    name = 'label2city'\n",
    "    gpu_ids = [0, 1, 2, 3]\n",
    "    checkpoints_dir = './checkpoints'\n",
    "    model = 'pix2pixHD'\n",
    "    norm = 'instance'\n",
    "    use_dropout = True\n",
    "    verbose = True\n",
    "    batchSize = 1\n",
    "    loadSize = 512\n",
    "    fineSize = 512\n",
    "    label_nc = 20\n",
    "    input_nc = 3\n",
    "    output_nc = 3\n",
    "    dataroot = '../../after_vton_difficult_v2'\n",
    "    datapairs = 'single_person2.txt'\n",
    "    resize_or_crop = 'scale_width'\n",
    "    serial_batches = True\n",
    "    no_flip = True\n",
    "    nThreads = 2\n",
    "    max_dataset_size = float(\"inf\")\n",
    "    display_winsize = 512\n",
    "    tf_log = True\n",
    "    netG = 'global'\n",
    "    ngf = 64\n",
    "    n_downsample_global = 4\n",
    "    n_blocks_global = 4\n",
    "    n_blocks_local = 3\n",
    "    n_local_enhancers = 1\n",
    "    niter_fix_global = 0\n",
    "    continue_train = True\n",
    "    display_freq = 100\n",
    "    print_freq = 100\n",
    "    save_latest_freq = 1000\n",
    "    save_epoch_freq = 10 \n",
    "    no_html = True\n",
    "    debug = True\n",
    "    load_pretrain = '../label2city'\n",
    "    which_epoch = 'latest'\n",
    "    phase = 'test'\n",
    "    niter = 100\n",
    "    niter_decay = 100\n",
    "    beta1 = 0.5\n",
    "    lr = 0.0002\n",
    "    num_D = 2\n",
    "    n_layers_D = 3\n",
    "    ndf = 64\n",
    "    lambda_feat = 10.0\n",
    "    no_ganFeat_loss = True\n",
    "    no_vgg_loss = False\n",
    "    no_lsgan = True\n",
    "    pool_size = 0\n",
    "    isTrain = True\n",
    "\n",
    "opt = Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(data.Dataset):\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        super(BaseDataset, self).__init__()\n",
    "        \n",
    "        human_names = []\n",
    "        cloth_names = []\n",
    "        with open(os.path.join(opt.dataroot, opt.datapairs), 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                h_name, c_name = line.strip().split()\n",
    "                human_names.append(h_name)\n",
    "                cloth_names.append(c_name)\n",
    "        self.human_names = human_names\n",
    "        self.cloth_names = cloth_names\n",
    "        \n",
    "    def image_for_pose(self, pose_name, transform):\n",
    "        with open(osp.join(pose_name), 'r') as f:\n",
    "            pose_label = json.load(f)\n",
    "            pose_data = pose_label['people'][0]['pose_keypoints']\n",
    "            pose_data = np.array(pose_data)\n",
    "            pose_data = pose_data.reshape((-1,3))\n",
    "        point_num = pose_data.shape[0]\n",
    "        fine_height = 256\n",
    "        fine_width = 192\n",
    "        pose_map = torch.zeros(point_num, fine_height, fine_width)\n",
    "        r = 5\n",
    "        im_pose = Image.new('L', (fine_width, fine_height))\n",
    "        pose_draw = ImageDraw.Draw(im_pose)\n",
    "        for i in range(point_num):\n",
    "            one_map = Image.new('L', (fine_width, fine_height))\n",
    "            draw = ImageDraw.Draw(one_map)\n",
    "            pointx = pose_data[i,0]\n",
    "            pointy = pose_data[i,1]\n",
    "            if pointx > 1 and pointy > 1:\n",
    "                draw.rectangle((pointx-r, pointy-r, pointx+r, pointy+r), 'white', 'white')\n",
    "                pose_draw.rectangle((pointx-r, pointy-r, pointx+r, pointy+r), 'white', 'white')\n",
    "            one_map = transform(one_map.convert('RGB'))\n",
    "            pose_map[i] = one_map[0]\n",
    "        return pose_map\n",
    "    \n",
    "    def getAgnostic(self, h_name, im_parse, im):\n",
    "        mask = Image.open(\n",
    "            osp.join(self.opt.dataroot, self.opt.phase ,self.opt.phase + '_imgmask', h_name.replace('.jpg', '.png'))).convert('L')       \n",
    "        mask_array  = np.array(mask)\n",
    "        parse_shape = (mask_array > 0).astype(np.float32)\n",
    "        parse_shape_ori = Image.fromarray((parse_shape*255).astype(np.uint8))\n",
    "        parse_shape = parse_shape_ori\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "        shape = transform(parse_shape)  # [-1,1]\n",
    "        parse_array = np.array(im_parse)\n",
    "\n",
    "        parse_head = (parse_array == 1).astype(np.float32) + \\\n",
    "                (parse_array == 4).astype(np.float32) + \\\n",
    "                (parse_array == 13).astype(\n",
    "                    np.float32)\n",
    "\n",
    "        phead = torch.from_numpy(parse_head)  # [0,1]\n",
    "        im = transform(im)  # [-1,1]\n",
    "        im_h = im * phead - (1 - phead)  # [-1,1], fill -1 for other parts\n",
    "        return shape, im_h\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        c_name = self.cloth_names[index]\n",
    "        h_name = self.human_names[index]\n",
    "        A_path = osp.join(self.opt.dataroot, self.opt.phase ,self.opt.phase + '_label', h_name.replace(\".jpg\", \".png\"))\n",
    "        label = Image.open(A_path).convert('L')\n",
    "\n",
    "        B_path = osp.join(self.opt.dataroot, self.opt.phase ,self.opt.phase + '_img', h_name)\n",
    "        image = Image.open(B_path).convert('RGB') \n",
    "        mask = Image.open(B_path).convert('L')\n",
    "        \n",
    "        E_path = osp.join(self.opt.dataroot, self.opt.phase ,self.opt.phase + '_edge', c_name)\n",
    "        edge = Image.open(E_path).convert('L')\n",
    "                \n",
    "        C_path = osp.join(self.opt.dataroot, self.opt.phase ,self.opt.phase + '_color', c_name)\n",
    "        color = Image.open(C_path).convert('RGB')\n",
    "        \n",
    "        S_path = osp.join(self.opt.dataroot, self.opt.phase ,self.opt.phase + '_posergb', h_name)\n",
    "        skeleton = Image.open(S_path).convert('RGB')\n",
    "        \n",
    "        transform_A = get_transform(method=Image.NEAREST, normalize=False)\n",
    "        label_tensor = transform_A(label) * 255\n",
    "        transform_B = get_transform()      \n",
    "        image_tensor = transform_B(image)\n",
    "        mask_tensor = transform_A(image)\n",
    "        edge_tensor = transform_A(edge)\n",
    "        color_tensor = transform_B(color)\n",
    "        skeleton_tensor = transform_B(skeleton)\n",
    "        pose_name = osp.join(self.opt.dataroot, self.opt.phase ,self.opt.phase + '_pose', h_name.replace('.jpg', '_keypoints.json'))\n",
    "        pose_map = self.image_for_pose(pose_name, transform_B)\n",
    "        shape, im_h = self.getAgnostic(h_name, label, image)\n",
    "        agnostic = torch.cat([shape, im_h, skeleton_tensor], 0)\n",
    "        blurry_mask =  shape\n",
    "        return {'label': label_tensor, 'image': image_tensor, \n",
    "                             'edge': edge_tensor,'color': color_tensor, \n",
    "                             'mask': mask_tensor, 'name' : c_name,\n",
    "                             'colormask': mask_tensor, 'skeleton': skeleton_tensor, 'pose':pose_map,\n",
    "                             'agnostic': agnostic, 'blurry': blurry_mask}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.human_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = BaseDataset(opt)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "            t,\n",
    "            batch_size=opt.batchSize,\n",
    "            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = networks.define_Refine(37, 14, self.gpu_ids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "improve",
   "language": "python",
   "name": "improve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
