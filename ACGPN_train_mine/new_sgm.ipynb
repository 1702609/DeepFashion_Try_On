{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import ImageDraw\n",
    "from data.base_dataset import BaseDataset, get_params, get_transform\n",
    "import models.networks as networks\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    name = 'label2city'\n",
    "    gpu_ids = [0, 1, 2, 3]\n",
    "    checkpoints_dir = './checkpoints'\n",
    "    model = 'pix2pixHD'\n",
    "    norm = 'instance'\n",
    "    use_dropout = True\n",
    "    verbose = True\n",
    "    batchSize = 1\n",
    "    loadSAize = 512\n",
    "    fineSize = 512\n",
    "    label_nc = 20\n",
    "    input_nc = 3\n",
    "    output_nc = 3\n",
    "    dataroot = '../../longshortV2'\n",
    "    datapairs = 'train_pairs.txt'\n",
    "    resize_or_crop = 'scale_width'\n",
    "    serial_batches = True\n",
    "    no_flip = True\n",
    "    nThreads = 2\n",
    "    max_dataset_size = float(\"inf\")\n",
    "    display_winsize = 512\n",
    "    tf_log = True\n",
    "    netG = 'global'\n",
    "    ngf = 64\n",
    "    n_downsample_global = 4\n",
    "    n_blocks_global = 4\n",
    "    n_blocks_local = 3\n",
    "    n_local_enhancers = 1\n",
    "    niter_fix_global = 0\n",
    "    continue_train = True\n",
    "    display_freq = 100\n",
    "    print_freq = 100\n",
    "    save_latest_freq = 1000\n",
    "    save_epoch_freq = 10 \n",
    "    no_html = True\n",
    "    debug = True\n",
    "    load_pretrain = '../label2city'\n",
    "    which_epoch = 'latest'\n",
    "    phase = 'test'\n",
    "    niter = 100\n",
    "    niter_decay = 100\n",
    "    beta1 = 0.5\n",
    "    lr = 0.0002\n",
    "    num_D = 2\n",
    "    n_layers_D = 3\n",
    "    ndf = 64\n",
    "    lambda_feat = 10.0\n",
    "    no_ganFeat_loss = True\n",
    "    no_vgg_loss = False\n",
    "    no_lsgan = True\n",
    "    pool_size = 0\n",
    "    isTrain = True\n",
    "\n",
    "opt = Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dir):\n",
    "    images = []\n",
    "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
    "\n",
    "    f = dir.split('/')[-1].split('_')[-1]\n",
    "    dirs= os.listdir(dir)\n",
    "    for img in dirs:\n",
    "\n",
    "        path = os.path.join(dir, img)\n",
    "        #print(path)\n",
    "        images.append(path)\n",
    "    return images\n",
    "\n",
    "def get_params(opt, size):\n",
    "    w, h = size\n",
    "    new_h = h\n",
    "    new_w = w\n",
    "    if opt.resize_or_crop == 'resize_and_crop':\n",
    "        new_h = new_w = opt.loadSize            \n",
    "    elif opt.resize_or_crop == 'scale_width_and_crop':\n",
    "        new_w = opt.loadSize\n",
    "        new_h = opt.loadSize * h // w\n",
    "\n",
    "    x = random.randint(0, np.maximum(0, new_w - opt.fineSize))\n",
    "    y = random.randint(0, np.maximum(0, new_h - opt.fineSize))\n",
    "\n",
    "def get_transform(method=Image.BICUBIC, normalize=True):\n",
    "        transform_list = []\n",
    "        transform_list += [transforms.ToTensor()]\n",
    "        if normalize:\n",
    "            transform_list += [transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                    (0.5, 0.5, 0.5))]\n",
    "        return transforms.Compose(transform_list)\n",
    "    \n",
    "class BaseDataset(data.Dataset):\n",
    "    def __init__(self, opt):\n",
    "        self.opt = opt\n",
    "        super(BaseDataset, self).__init__()\n",
    "        dir_label = os.path.join(opt.dataroot, 'test', opt.phase + '_label')\n",
    "        self.labels = make_dataset(dir_label)\n",
    "        dir_img = os.path.join(opt.dataroot, 'test',opt.phase + '_img')\n",
    "        self.images = make_dataset(dir_img)\n",
    "        dir_edge = os.path.join(opt.dataroot, 'test',opt.phase + '_edge')\n",
    "        self.edges = make_dataset(dir_edge)\n",
    "        dir_color = os.path.join(opt.dataroot,'test', opt.phase + '_color')\n",
    "        self.colors = make_dataset(dir_color)\n",
    "        dir_pose = os.path.join(opt.dataroot,'test', opt.phase + '_pose')\n",
    "        self.pose = make_dataset(dir_pose)\n",
    "        dir_cwarp = os.path.join(opt.dataroot,'test', opt.phase + '_cwarp')\n",
    "        self.cwarp = make_dataset(dir_cwarp)\n",
    "        dir_mwarp = os.path.join(opt.dataroot, 'test',opt.phase + '_mwarp')\n",
    "        self.mwarp = make_dataset(dir_mwarp)\n",
    "        \n",
    "    def image_for_pose(self, index, transform):\n",
    "        with open(self.pose[index], 'r') as f:\n",
    "            pose_label = json.load(f)\n",
    "            pose_data = pose_label['people'][0]['pose_keypoints']\n",
    "            pose_data = np.array(pose_data)\n",
    "            pose_data = pose_data.reshape((-1,3))\n",
    "        point_num = pose_data.shape[0]\n",
    "        fine_height = 256\n",
    "        fine_width = 192\n",
    "        pose_map = torch.zeros(point_num, fine_height, fine_width)\n",
    "        r = 5\n",
    "        im_pose = Image.new('L', (fine_width, fine_height))\n",
    "        pose_draw = ImageDraw.Draw(im_pose)\n",
    "        for i in range(point_num):\n",
    "            one_map = Image.new('L', (fine_width, fine_height))\n",
    "            draw = ImageDraw.Draw(one_map)\n",
    "            pointx = pose_data[i,0]\n",
    "            pointy = pose_data[i,1]\n",
    "            if pointx > 1 and pointy > 1:\n",
    "                draw.rectangle((pointx-r, pointy-r, pointx+r, pointy+r), 'white', 'white')\n",
    "                pose_draw.rectangle((pointx-r, pointy-r, pointx+r, pointy+r), 'white', 'white')\n",
    "            one_map = transform(one_map.convert('RGB'))\n",
    "            pose_map[i] = one_map[0]\n",
    "            return pose_map\n",
    "    \n",
    "    def __getitem__(self, index):        \n",
    "        label = Image.open(self.labels[index]).convert('L')\n",
    "        image = Image.open(self.images[index]).convert('RGB')\n",
    "        mask = Image.open(self.images[index]).convert('L')\n",
    "        edge = Image.open(self.edges[index]).convert('L')\n",
    "        wedge = Image.open(self.mwarp[index]).convert('L')\n",
    "        color = Image.open(self.colors[index]).convert('RGB')\n",
    "        wcolor = Image.open(self.cwarp[index]).convert('RGB')\n",
    "        \n",
    "        transform_A = get_transform(method=Image.NEAREST, normalize=False)\n",
    "        label_tensor = transform_A(label) * 255\n",
    "        transform_B = get_transform()      \n",
    "        image_tensor = transform_B(image)\n",
    "        mask_tensor = transform_A(image)\n",
    "        edge_tensor = transform_A(edge)\n",
    "        wedge_tensor = transform_A(wedge)\n",
    "        color_tensor = transform_B(color)\n",
    "        wcolor_tensor = transform_B(wcolor)\n",
    "        pose_map = self.image_for_pose(index, transform_B)\n",
    "        \n",
    "        return {'label': label_tensor, 'image': image_tensor, \n",
    "                             'edge': edge_tensor,'color': color_tensor, \n",
    "                             'mask': mask_tensor, \n",
    "                             'colormask': mask_tensor,'pose':pose_map,\n",
    "                             'wedge' : wedge_tensor, 'wcolor' : wcolor_tensor}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    G1_old = networks.define_Refine(37, 14, opt.gpu_ids).eval()\n",
    "save_filename = '%s_net_%s.pth' % (opt.which_epoch, 'G1')\n",
    "save_path = os.path.join(opt.load_pretrain, save_filename)\n",
    "G1_old.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    G1_new = networks.define_Refine(37, 14, opt.gpu_ids).eval()\n",
    "save_filename = 'custom_G1.pth'\n",
    "save_path = os.path.join(opt.load_pretrain, save_filename)\n",
    "G1_new.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = BaseDataset(opt)\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    t,\n",
    "    batch_size=opt.batchSize,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def changearm(old_label):\n",
    "    label=old_label\n",
    "    arm1=torch.FloatTensor((label.cpu().numpy()==11).astype(np.int))\n",
    "    arm2=torch.FloatTensor((label.cpu().numpy()==13).astype(np.int))\n",
    "    noise=torch.FloatTensor((label.cpu().numpy()==7).astype(np.int))\n",
    "    label=label*(1-arm1)+arm1*4\n",
    "    label=label*(1-arm2)+arm2*4\n",
    "    label=label*(1-noise)+noise*4\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-c5e6cbd117a1>:3: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  arm1=torch.FloatTensor((label.cpu().numpy()==11).astype(np.int))\n",
      "<ipython-input-19-c5e6cbd117a1>:4: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  arm2=torch.FloatTensor((label.cpu().numpy()==13).astype(np.int))\n",
      "<ipython-input-19-c5e6cbd117a1>:5: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  noise=torch.FloatTensor((label.cpu().numpy()==7).astype(np.int))\n"
     ]
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    all_clothes_label = changearm(data['label'])\n",
    "    mask_clothes = torch.FloatTensor((data['label'].cpu().numpy() == 4).astype(np.int))\n",
    "    mask_fore = torch.FloatTensor((data['label'].cpu().numpy() > 0).astype(np.int))\n",
    "    img_fore = data['image'] * mask_fore\n",
    "\n",
    "    in_label = Variable(data['label'].cuda())\n",
    "    in_edge = Variable(data['edge'].cuda())\n",
    "    in_wedge = Variable(data['wedge'].cuda())\n",
    "    in_img_fore = Variable(img_fore.cuda())\n",
    "    in_mask_clothes = Variable(mask_clothes.cuda())\n",
    "    in_color = Variable(data['color'].cuda())\n",
    "    in_wcolor = Variable(data['wcolor'].cuda())\n",
    "    in_all_clothes_label = Variable(all_clothes_label.cuda())\n",
    "    in_image = Variable(data['image'].cuda())\n",
    "    in_pose = Variable(data['pose'].cuda())\n",
    "    in_image2 = Variable(data['image'].cuda())\n",
    "    in_mask_fore = Variable(mask_fore.cuda()) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_input(label_map, clothes_mask, all_clothes_label):\n",
    "\n",
    "    size = label_map.size()\n",
    "    oneHot_size = (size[0], 14, size[2], size[3])\n",
    "    input_label = torch.cuda.FloatTensor(torch.Size(oneHot_size)).zero_()\n",
    "    input_label = input_label.scatter_(1, label_map.data.long().cuda(), 1.0)\n",
    "\n",
    "    masked_label = torch.cuda.FloatTensor(torch.Size(oneHot_size)).zero_()\n",
    "    masked_label = masked_label.scatter_(1, (label_map * (1 - clothes_mask)).data.long().cuda(), 1.0)\n",
    "\n",
    "    c_label = torch.cuda.FloatTensor(torch.Size(oneHot_size)).zero_()\n",
    "    c_label = c_label.scatter_(1, all_clothes_label.data.long().cuda(), 1.0)\n",
    "\n",
    "    input_label = Variable(input_label)\n",
    "\n",
    "    return input_label, masked_label, c_label\n",
    "\n",
    "input_label, masked_label, all_clothes_label = encode_input(in_label, in_mask_clothes, in_all_clothes_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def gen_noise(shape):\n",
    "    noise = np.zeros(shape, dtype=np.uint8)\n",
    "    ### noise\n",
    "    noise = cv2.randn(noise, 0, 255)\n",
    "    noise = np.asarray(noise / 255, dtype=np.uint8)\n",
    "    noise = torch.tensor(noise, dtype=torch.float32)\n",
    "    return noise.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-f06f26415afe>:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  arm1_mask = torch.FloatTensor((in_label.cpu().numpy() == 11).astype(np.float)).cuda()\n",
      "<ipython-input-23-f06f26415afe>:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  arm2_mask = torch.FloatTensor((in_label.cpu().numpy() == 13).astype(np.float)).cuda()\n",
      "<ipython-input-23-f06f26415afe>:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  pre_clothes_mask=torch.FloatTensor((in_edge.detach().cpu().numpy() > 0.5).astype(np.float)).cuda()\n"
     ]
    }
   ],
   "source": [
    "arm1_mask = torch.FloatTensor((in_label.cpu().numpy() == 11).astype(np.float)).cuda()\n",
    "arm2_mask = torch.FloatTensor((in_label.cpu().numpy() == 13).astype(np.float)).cuda()\n",
    "pre_clothes_mask=torch.FloatTensor((in_edge.detach().cpu().numpy() > 0.5).astype(np.float)).cuda()\n",
    "clothes = in_color * pre_clothes_mask\n",
    "\n",
    "shape = pre_clothes_mask.shape\n",
    "\n",
    "G1_in = torch.cat([pre_clothes_mask, clothes, all_clothes_label, in_pose, gen_noise(shape)], dim=1)\n",
    "arm_label = G1_old.refine(G1_in) #input data into G1 (cGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-de18bc9c1467>:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  pre_clothes_mask=torch.FloatTensor((in_wedge.detach().cpu().numpy() > 0.5).astype(np.float)).cuda()\n"
     ]
    }
   ],
   "source": [
    "pre_clothes_mask=torch.FloatTensor((in_wedge.detach().cpu().numpy() > 0.5).astype(np.float)).cuda()\n",
    "clothes = in_wcolor * pre_clothes_mask\n",
    "G1_new_in = torch.cat([pre_clothes_mask, clothes, all_clothes_label, in_pose, gen_noise(shape)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "arm_label_new = G1_new.refine(G1_new_in) #input data into G1 (cGAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_plain(inputs):\n",
    "    size = inputs.size()\n",
    "    pred_batch = []\n",
    "    for input in inputs:\n",
    "        input = input.view(1, 14, 256,192)\n",
    "        pred = np.squeeze(input.data.max(1)[1].cpu().numpy(), axis=0)\n",
    "        pred_batch.append(pred)\n",
    "\n",
    "    pred_batch = np.array(pred_batch)\n",
    "    pred_batch = torch.from_numpy(pred_batch)\n",
    "    label_batch = pred_batch.view(size[0], 1, 256,192)\n",
    "\n",
    "    return label_batch\n",
    "\n",
    "def generate_label_color(inputs):\n",
    "    label_batch = []\n",
    "    for i in range(len(inputs)):\n",
    "        label_batch.append(util.tensor2label(inputs[i], opt.label_nc))\n",
    "    label_batch = np.array(label_batch)\n",
    "    label_batch = label_batch * 2 - 1\n",
    "    input_label = torch.from_numpy(label_batch)\n",
    "    return input_label\n",
    "\n",
    "def generate_discrete_label(inputs, label_nc, onehot=True, encode=True):\n",
    "    pred_batch = []\n",
    "    size = inputs.size()\n",
    "    for input in inputs:\n",
    "        input = input.view(1, label_nc, size[2], size[3])\n",
    "        pred = np.squeeze(input.data.max(1)[1].cpu().numpy(), axis=0)\n",
    "        pred_batch.append(pred)\n",
    "    pred_batch = np.array(pred_batch)\n",
    "    pred_batch = torch.from_numpy(pred_batch)\n",
    "    label_map = []\n",
    "    for p in pred_batch:\n",
    "        p = p.view(1, 256, 192)\n",
    "        label_map.append(p)\n",
    "    label_map = torch.stack(label_map, 0)\n",
    "    if not onehot:\n",
    "        return label_map.float().cuda()\n",
    "    size = label_map.size()\n",
    "    oneHot_size = (size[0], label_nc, size[2], size[3])\n",
    "    input_label = torch.cuda.FloatTensor(torch.Size(oneHot_size)).zero_()\n",
    "    input_label = input_label.scatter_(1, label_map.data.long().cuda(), 1.0)\n",
    "    return input_label\n",
    "\n",
    "armlabel_map = generate_discrete_label(arm_label.detach(), 14, False)\n",
    "armlabel_map_new = generate_discrete_label(arm_label_new.detach(), 14, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAACyCAYAAAC5ko9NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnnUlEQVR4nO2deZxU1bXvv6uqeu6GZoZuRhVUEIKKimPUaBySiOaZRE2i5nqfMdEXk5jca/Ley3Bfcq8ZvHnXmOsVXxI1g8QhiQOOkDgjComCgAgyNw3N0A1NNz1U1Xp/nNNQTdfYNZ9a38+nPlW19z77rFO/c1bteYuqYhiGYXgLX74NMAzDMDKPOXfDMAwPYs7dMAzDg5hzNwzD8CDm3A3DMDyIOXfDMAwPYs7dRUTuF5EfxIlXETkmlzYZhmEMFnPuhmGULCJyrohsy7cd2cCcu2EYhgcpKecuIseLyIsi0iYiq0TksjhpvykizSKyXUT+IUG+14vIBhFpF5GNIvJZN9wvIneKyG43/Ba3eSfgxr8oIj8QkddF5ICIPCkiI0TkdyKyX0TeEpHJGf0RPIKIbBKRb4jIChHZJyJ/EJHKiPiPi8jbrtavi8gsN/wLIvJkRLp1IvJIxPetIjI7yvkqReS3IrLHzfMtERnjxk0RkZdd/ReJyC9E5Ldu3GRX8y+4ebeKyE0icopre5uI3J3Fn8oAROQkEfm7q9Ej7v3yM+AZoMF9/g6ISEO+bc0YqloSL6AMWA98GygHzgfagWPd+PuBH7ifLwZ2AicANcDvAQWOiZJvDbA/Ip9xwAz3803AamA8MAxY5OYTcONfdG06Ghjqpn0fuAAIAA8Cv873b1eIL2AT8CbQAAwH1gA3uXEnAi3AaYAfuM5NXwEcBbThFGwagM3ANve4o4BWwBflfF8EngSq3TxPBoa4cUuAn7r31Vnu/fBbN26yq/l/AZXAR4Eu4M/AaKDRtfXD+f5NvfpyddkM3Or6gU8CPcAPgHP79Pfaq5RK7nOBWuAOVe1R1b8ATwFXR0n7aRyn+q6qdgDfS5B3GDhBRKpUtVlVV0Xk8x+quk1VW4E7ohz7a1X9QFX34ZQiPlDVRaoaBB7BcVRGdO5S1e2quhfH8c52w28E7lXVpaoaUtUHgG5grqpuwPlTnw2cAzwHbBeR44APA6+oajjKuXqBETh/8CFVXa6q+0VkInAK8B33vnoVeCLK8f9HVbtU9XmgA3hIVVtUtQl4BdM5m8zFKSzdpaq9qvpHnIKBpykl594AbD3iwd2MU3KKmvaIdFFxnf9ncErpzSKy0HUU0fLZeuTxODWEPg5G+V4b69wGOyI+d3L4t5oE3OY2ebSJSBswAUcPgJdwSmznuJ9fxHHsH3a/R+M3OH8EC9ymuh+LSJmb515V7YxIazoXFg1Ak7rFeJdoGnmKUnLu24EJIhJ5zROBpihpm3GcQWS6mKjqc6p6IU6TzHvAfRH5jI9IOuHIY42ssBX4oarWR7yqVfUhN77PuZ/tfn6JBM7dLfF9X1WnA2cAHweuxdF4uIhURyQ3nQuLZqBRRCQirE8jzy6LW0rOfSlO6e6fRKRMRM4FPgEsiJL2YeB6EZnuPrTfjZWpiIwRkXkiUoNT9T+A00zTl8+tItIoIvXAP2fqYoy43AfcJCKniUONiHxMROrc+JeA84AqVd2G0yxyMU6zy9+jZSgi54nITBHx47Sp9wJhVd0MLAO+JyLlInI6zn1lFA5LgBBwi4gERGQecKobtxMYISJD82ZdligZ566qPTgP3SXAbuA/gWtV9b0oaZ8B/i/wF5wOz7/EydoHfB2nZrAXp/T3JTfuPuB5YAWO03gaCOLcaEaWUNVlwH8H7sbpIF0PXB8R/z7On/Ar7vf9wAbgNVWNpc1Y4FEcx74G5w/iN27cZ4HTgT04nXR/wPmjNwoA99n/JHADTmf653D627rd5/8hYIPbhOeZ0TLSvxnKyCYicgnwX6o6Kd+2GNlDRP4AvKeqMWt8Rn4RkaU4z+Kv821LtiiZkns+EJEqEbnUrQo24jTv/CnfdhmZxR2zfrSI+ETkYmAezlBHo0AQkQ+LyFj3WbwOmAU8m2+7sknWnLuIXCwia0VkvYjcnq3zFDgCfB+naeDvONX57+TVojQxXaMyFmfEzQHgLuBLqhq17b5QKQFdjwXewWmWuQ24UlWb82pRlslKs4zb6fQ+cCGwDXgLuFpVV2f8ZEbOMF29ienqTbJVcj8VWK+qG9zOjAU4VVWjuDFdvYnp6kGy5dwb6T9JYBvRJwsZxYXp6k1MVw8SyNeJReRGnGni+PGfXM2QfJnSZxDi94Gk83+nEAxRzCOQ2mndraqjBnu86VqYpKsrmLaFSBcd9Gi3RIvLlnNvov8svfEcMRNUVecD8wGGyHA9TT6SJVOSwz9iOFJZmThhIsJhgjt3Qbg4h7Iv0kdjLrWA6VqyuoJpW4gs1cUx47Ll3N8CporIFJyb5CrgmiydK238w4bFvklEIOAHoOX8Rg6O6v8nOXJFLzVrdkJv0Anw+fDX1hDavz+bJucL09V0LQhM28RkxbmralBEbsFZaMkP/CpipcSCQioqkOqqGJHCnnMncP5trwNwTt1zjPX3vwGWd03ijf1H896PTmDIUqfZUmqq4UBHUZYE4mG6mq6FgGmbHFlrc1fVp3Gm2xc0vtqamHG7z5/IJ7+5iItq342Z5uTKzZxcuZkX/mUHT3znAudm8Xl3bpjp6k2KRVcwbZPFe1eUCj4/Ul4eI85H7bVNcW+SSC6sWc1l/7KIfXOdpkspy1tftWG6ehfTNmlK2rmL3x/3H3tGfWoT2C6sWU3TJU61zlddnSC1kS1MV+9i2iZPSTt335DY+yPsPm8Cl9avSDnP2hGdUFGOVJSDz5+OecYgMV29i2mbPCXr3KWsPG5ve+vxDOiISYY7Zz5C77h68PsRX9Thp0YWMV29i2mbGiXr3ON1yhDwc+XFr+XOGCNjmK7exbRNjZJ17vHYfXYjc2vXD+rYIb4uNl/sDtNKa+ackWlMV+9i2g7EO1eSAhIIQHlZzPiOBmFioHVQeVdKkODkLiBBScPIOKardzFtU6cknbuvrs65WaIhQm9thtaZ8FD7XTFgunoX0zZ1Ss+5+/xxSwCUl3HVZS/nzh4jM5iu3sW0HRQl59zFJ3FLAC0fHsesqq3R442CxXT1Lqbt4Cg55x6PcH0dV3ztLxxdtivfphgZxHT1LqZtbMy591FRzsbvlHFBXXJTl40iwXT1LqZtXMy5u4Trqrh91nOUE863KUYGMV29i2kbH3PuLpuuGMZx5elvht6lASrei7EcqZFzTFfvYtrGx5y7y6SF7fzr1o+lnc+De85k0lPOeFvt6U07PyM9TFfvYtrGx5y7i3/7Hta+MiXtfJ55eya+3fsA0IMH087PSA/T1buYtvEx5x7BpGcOsrxr0qCPv3/vmUz5g7X/FRqmq3cxbWOTlnMXkU0islJE3haRZW7YcBF5QUTWue/DMmNq9inbsps7f/dJWkKxlxWNRYeW8fwfT6VqjdMGqF1daDCYaRNzhpe0NV0P4yVdwbSNRyZK7uep6mxVneN+vx1YrKpTgcXu9+IgHGbK/Zu546ZruXrZP7IlmNw9vl8ruO6PX2bK77YdzupAR7aszCXe0NZ0PRJv6AqmbRyysa/UPOBc9/MDwIvAP2fhPNlBlfKXVjJxUQ/f/fL1NH56IxNrWrlx5EtRkz/V/iEeeOY8jr2n6fBu6oD2eqcEEEHxamu6xqN4dQXTNgaiOvgFd0RkI9AKKHCvqs4XkTZVrXfjBWjt+37EsTcCNwJUUn3yWXLpoO1IyeZAAP+Y0XHTaOdBQq2HV5gLjBvLvjOjt+vVbu7Ev31P/+O7ugjt2Zu+sXlgkT66XFXnDFZb07UwSVdXN860LTCW6mL2696oq52lW3I/S1WbRGQ08IKIvBcZqaoqIlH/PVR1PjAfYIgMz9CSbtkh2LyDmkd3RI3z1Q+FmiOWCfVGCWBQ2pquBY89s97Vth9ptbmrapP73gL8CTgV2Cki4wDc95Z0jSwqQiFCHmi7M22PwHT1Lh7R9kgG7dxFpEZE6vo+Ax8F3gWeAK5zk10HPJ6ukZlEqrI7Ey3U2gbhUFbPkW2KUVvTNTHFqCuYtoMlnWaZMcCfnCY6AsDvVfVZEXkLeFhEbgA2A59O38zMIRXlmc0wfLh2qp0H0e7uzOafH4pOW9M1KYpOVzBtB8ugnbuqbgA+FCV8D/CRdIzKFlJWjlRUZDTPUHs7vpDzrx/u7Mxo3vmi2LQ1XZOj2HQF0zYdsjEUsmDxDUl9okNCVAl3eK+9rpgwXb2LaTt4Smf5AZ8fYu3mYhQvpqt3MW3TomScu6+mOvZWXUbRYrp6F9M2PUrGuWe8U8YoCExX72LapkfJOPfQnr2E97dDyHtDnkoZ09W7mLbpUTLOHVXC7e2EO7zbO16SmK7exbRNi9Jx7i5eWozfOIzp6l1M28FRes49GPTspIVSxnT1Lqbt4Cg55w5AKP7OK1JR7gzDMooL09W7mLYpU5LOPeGsNL8fKbMhWPnGP/UopCz5EROmq3cxbVOnJJ17Mr3vvroszIwzksY/ahSnPLqWdT86Kfnp56ardzFtU6YknbuGFcKJqnkVGV/Twkgeqazgs/VvsvozP2fLN09O6hjT1buYtqlTks6dcAjtStxB4x9Wb+14eWLLZybS4PdTIWV86eqFBMY3Jj7IdPUupm3KFL1zD4xvxDd7Ov7p0wiMHZPZzP1+/LU1idMZGefAMUFqfZUAfG7IGnqmxN9mLSVMV+9i2h6i6J376m838vsn/x+XPfoaa741JfNrUZSXZTY/I2WG+avZ8MUMZ2q6ehfTFvCAc8cHQ3yVTK9s4rYLF9L8P05NysEnOzFCKirwDxmSrpVGmtww6/WkmmZMV+9i2qZG8Tt3wC8+zqmEm4Zu5tmv/ZjwqTMSHhPu7k56YoRUV9nqdHnmK8PfoWfyqITpTFfvYtqmRkLnLiK/EpEWEXk3Imy4iLwgIuvc92FuuIjIXSKyXkRWiMhJ2TT+SPziY1ygluk/X5W4lKdKaG9bwh54J2O/s2O6x1ily3hJn2SJPh8Z7C9EbWt9lWz/Wm/izjLTtah0TQnTNiWSKbnfD1x8RNjtwGJVnQosdr8DXAJMdV83AvdkxszUuHPsm2y5ZlLihOEQ4X37k7pZJBDwXC98A5M4kbOODB5HgWq76JR70bknJE5ouhaVrilR4tqmQkLnrqovA3uPCJ4HPOB+fgC4PCL8QXV4A6gXkXEZsjVp/OJjyPk7wNkIOC7hzk40mVXn/H58NdUZsK5wGCajKGPADNB6ClTbcYFamm4Lmq4JKDZdU6WUtU2Fwba5j1HVZvfzDpxd1QEaga0R6ba5YQMQkRtFZJmILOsl84sCPTr9QXbcenpSjiDU3p5UW55UVmbCtEInkI622db1uVPuRU+flVRa07UfaekK2dc2FUzbxKTdoaqqCuggjpuvqnNUdU4ZmZ9VNi5Qy8Kv/5jwmQM2e49mDHqgI35VLxQi3LYvcwYWAYPRNtu6ju8rvSdnjOkahUJ9ZlM0xrRNwGCd+86+qpv73uKGNwETItKNd8PywvhALTtPq06uGt/VRWjX7oGlgVAI7eoitKcV7e3JkqUFRbDQtX1qzr3ombOTSmu6HqLgdU0V0zY+g3XuTwDXuZ+vAx6PCL/W7YGfC+yLqArmhce/8mO6n5tE63WnE5g0IW5aDQYJ7dlLaGfLoVewZTehPXtL6SZpo8C1nVJWS9PXe5NOn1dd585iy3fPKIQ1T9oocF0Hgz2zsUlmKORDwBLgWBHZJiI3AHcAF4rIOuAC9zvA08AGYD1wH/DlrFidAlPKannxhD/z5r/dw7CH2un+2CnxD1B1NgdwX4S9u3/jSl3KW/yVTtp5RRfSpBsBmikCbf80Zz7hs09M/oA86Kqnf4gRd27lv13xCv7hw7J+vj6KWddBUULPbCokHOWvqlfHiPpIlLQK3JyuUdnit5Nf5Cc/2sqiZ+rtBgBmymkDwtbo8pCqFry208pqCH5nL1WfG01oZ0viA3KMr7KS924o48rha9nSPSKn5y5mXY3M4YkZqkZp8tcZj9N0zTH5NiMqwVOO58tz/wpApa+X4ITEs2sNI5OUnHO/su4dWm4aWLIxipMFt/6U4EeSW+89l2y4ooKhfmctlNFl+9l4uW0kYeSWknPuU8pq+eItj6e0fZtRuBxfXs3uWXnvrOxHoLGBmSdv7BcWHBq2e87IKSXn3AF8kvIQX6OAufja1/NtQj+0poozR6zvF3bdWa/gb8jwfgOGEYeSdO6GtxhZ1o6/wBeJKpMQ4WF1+TbDKCFK0rmvOzgGNImV5Yyi4OvD1rF73vR8mxGXkWXtrL+msP+ADG9Rks79hftPd8bDFii+OivhpYJffPQMSTwLOWeEw7T2DtzqTf3WHGjkjpJy7t3ay/GvfZ4xbx7ItylR8Y8Yztb/dQabvzoz36YUFd3aS/vRhVMTC32wiQWvnp5vM4wSp6Sc+0/2zGTy59fBGyvybcoAei6aw7qfT+Qr1zxO18hwUuvhGA4/2TOTabe/nW8zDqOK9A7ULxzAdDVyRkk5918uO4twV1e+zRiAr66Oput7+eaJz+MT5VPnvEFgShKbjRhA4ep6JKarkUtKyrmPXVSYeyr6Ro3g6unLDn0fWdaO+ktKmrQoRF2HrRG6w2X9wkxXI5fYnZZnuj5xKjUPtjOurO1QWJmE2DfbpqsXM2MWbac91H+jCNPVyCXm3PPMtvN9XDBiTb+JVdW+Hpo/nEejjKxguhq5xJx7HglMnshFZ72dbzOMLKCdB3l5d2EuamaUBubc88iBE8YyrXpH1LiLT3sH/zFTcmyRkSlCO1vY8ObEAeGmq5ErzLnnkS2XOlX1aEyr3gEVttBUMVO9fWCnqulq5IpkdmL6lYi0iMi7EWHfE5EmEXnbfV0aEfctEVkvImtF5KJsGd7H0X8Isi1YmJOSCplVuoyX9EmW6POHwj7QVQCzTNfM0PjYJnYHc7/UbzRtgYZCeWaN3JDMGLL7gbuBB48I/5mq/jQyQESmA1cBM4AGYJGITFPVrG17VLG+hU4tzokhlS0Bwip5WaWygUlM4GhW8daRUTtVdXZkgOlaXMTRtiCeWSM3JCy5q+rLwN4k85sHLFDVblXdiLMv46lp2OdppjzUQnu4MnHCLDBMRlFG0s0DpusgCO3ew4NLz8j5eU1bA9Jrc79FRFa4zTZ9u/82Alsj0mxzw4xoaOwSux+lZ/TAxadywGjTNTNodzcVzf3b3POoK9gzW1IM1rnfAxwNzMbZVf3OVDMQkRtFZJmILOule5BmAMEgj+47iV6P1SIrfL18cJU/p+ccz9EAKykyXQ+OKNxxAeNf7KKld8ih7/nQ1aWFQnlmjZwwqKdCVXeqakhVw8B9HK7GNQETIpKOd8Oi5TFfVeeo6pwyBr9NWrB5B699bCqregp3Cd+YtOzm/rVzY0afePwmApMmxIzPNBXiNBEVm64XfmHJoM+Tbcrf3cq+YFW/sFzr6hIslGfWyA2Dcu4iMi7i6xVA30iaJ4CrRKRCRKYAU4E30zMxMdoTfThhoRNq20fX5thrt3905Go2fm5Czvbe7NaDkV+LRtcyKdxam7a389iKk/qF5VpXl8j2obxra2SfhKNlROQh4FxgpIhsA74LnCsiswEFNgFfBFDVVSLyMLAaCAI3W6/74PGJcuM1T/Ps82fDWyszmvdKXUoru+ilm1d0IUcxnVZ2AUwXkRWYrhkh3NVF1doKOO1wWDZ1hejaAuNFZCX2zJYMCZ27ql4dJfiXcdL/EPhhOkalilRVenbT62pfD9vPqWPcgFFt6TFTThsQ1sgUduiW1ao658g403XwjHqnl5beIYwu238oLFu6QnRt1+jyjdF0hfxoa2Sfwu2JShYR1t7SwIzcVnEzxoh3hN298bfVO3hyZ46sKSBS0PWh5YU9cq/69ff5oHPgapAlqauRM4reuQcaxnHvFffhl+K8lGG/eZPH7j6fA6H8jHcvVFLRdexfCm8990hC+/az9EnbOtHILcXpESPx+ZgQ2J84XaESDjF24Wb2hapiJpk8Zg+BxoYcGlUAJKlrSMNI4WyfGh1VAgcHBpekrkbOKH7nrkqvJnkZBdp8q50HeX77cTHjP9WwnObLSmx7tiR1/ZfdM6l/enUODMo8JamrkTOK3rmHduzkEy/dnDDdD3Yfx7Bn1uTAotQJtbbS+uaYuGm6PtKeI2sKg2R13dVTR2h/4dfc6raGovatlJquRu4oeueuwSB1f6tkXzhKvTeCHd1DCbXty5FVmedTU/+Onv6hfJuRM5LVdcn9J8WNLxSGPLs6aqdqqelq5I6id+4AjQvWs7E3/qW8+puTc2TN4KhpUjrDsUeGNJa3Eqwp7I7DTJOMrjU7intIdinqauQGTzj34DEN1Pl6Y8Z/f9d0Gh5al0OLUmfMn9bT1D0sbpqNV+ZlTZK8kUhXr1Bquhq5wRPOXUJhvrV1Hg8fGArAm929fGX7KTS7mz088sGJhHbtyqeJGeHq096wKnwE/7r7WIa+tinfZqSN6WpkA2/UB99Ywb6z4P7pF/Gz2cOp3dKF79W3ufpjX6N7qJ9Jf9lIoS8rFm7bx2OvncrtFzwZM83kyt08dF0F0wp3nayMsvPUasb4Y9+i73WMIbhjZw4tGjwydhQ1ga1R40pNVyM3eMO5u4RWv8+QiFFxFQvfogIK3rEDaG8P0x7o4NkPzeDiUatiphs1oTWHVuUP/8gRXH79S9T6Yk/uWrV7LCMp/JEyANs+MZbLa96IGV8quhq5wxPNMl5Bl73Llt8cE7djtVSQqio+Wx9/ccLa+fW5MSYDlLfH7zA3jExjzr3AGHn/cn7+wsUx42vKe/DV5G0nn4KhJdRBoKN4RsqYrkauMedeYGhvD8NXCN3hsqjxn2lcRusV3l+nZPtlExnjj317fnnTPAJ//VsOLUoP09XINebcC5CRj7zLkrajosb5RCn//E581dU5tiq3tM0MMtQXe72d5o4hcfegLURMVyOXmHMvQLSnh7ae2I7tMxOW0X6ph0t5IlARv8klcPfIHBmTOUpeVyOnmHMvQLS7m50LJtGr0Se3lEmIcEBybFXuCEyeyOPn/SJuGn9X8bS391Hquhq5JaFzF5EJIvJXEVktIqtE5FY3fLiIvCAi69z3YW64iMhdIrJeRFaISHEs/lFgjP79u/z05Uuyln+XdrJcX2KJPscSfZ4temgGrz/fuqrfx3BfMQxgTZ1S1tXILcmU3IPAbao6HZgL3Cwi04HbgcWqOhVY7H4HuARnk92pwI3APRm3ugQIt7cz+rXY09L3nCBO88UgEYSpzOJ0uYhTOI9tfMAB3Q8wDtM1a5iuRq5I6NxVtVlV/+Z+bgfWAI3APOABN9kDwOXu53nAg+rwBlAvIuMybXgpMGRTFx90jY4aN+WMLUgg+siLZKiQKoY4hTcCUkY1dXRzEKCefOvq83ZrYcnqauSUlJ4iEZkMnAgsBcaoarMbtQPoW5C8EYicZ73NDTsyrxtFZJmILOulO1W7SwLfaytYtmciYR1Ykvvo6DVs/cactEp5fRzUDtppYyjDAQL51nXtl0Yxzh9/1Ij6i7dtuhh1BXtmU0YEfP7+rwzomixJO3cRqQUeA76qqv3mfKuqkuI+R6o6X1XnqOqcMipSOTQl/CNHEDrvJGTOCVk7R9YIh6j4SiX33j1vQFStv4tjL1mXVikPIKhBVrCEY5lNQPrnlS9ddVhvwr1T9bbdpmscMq2re5w9s0kSGN/Ixt/PIvxCQ7/Xht99CEli0/eM2JBMIhEpw3Hsv1PVP7rBO0VknKo2u9W4Fje8CZgQcfh4Nyzn+EeOYP3Xp+E75gC9PWXIzrkAjFoOtVu6DqUr37qH4Oboizrlm9Dq96mbVh817vThG/jzFRdS+3DsNUviEdYwK1jCWCYyWg4V1oKFrmtLqIPa8m7Wf6nXdI1CseoK3nhmAdrnNPKN2U8NCN83piotbVMhoXMXEQF+CaxR1X+PiHoCuA64w31/PCL8FhFZAJwG7IuoDuaU3hkT8R3jLPtbVh6ECc4IjNYJELlMU3frWAJt4zN+/upmYezr0bdR23F6HZ0NTuFp5DvKkAVvQTi14X1D/QfpqhdqB2GbqrKaZdRQxySZFhnVRgHrGtIwZyz4BoFJpms0ilXXPuyZzRzJlNzPBD4PrBSRt92wb+PcJA+LyA3AZuDTbtzTwKXAeqAT+EImDU6FprOrgMR7VFYM64L4+2QMiu4psPmMWLHt9I2Z2DmmnOFLxhPcuDnlc5RdvovAoskEN2xK6bh97GEHW6hlKG/oCwAcwwkAzcCF+dI1MHkid5zxaMx4v/jwT+xIKi/TtXB0TRZ7ZjNHQueuqq8CsXoBPhIlvQKJdzbONiJ0jwiTXstlbiiv7mHPmeMYOogb5R+mvM6/Xz+PSd/bmlIpol5GcgFXDoxQQqqaN121upLzq7YD0RfRWtHTRXVlDwe7C19Z0zVF7JnNKN4acyZCYPLEfFuRc86+aAW+Gm+sSSJdPZyy8Gt8d9cMevXwjf92dzff3zWdec9+hf0b6vNnYA7xkq5Gf3KhbdFv1iGBAKEzZ9J8aw/Dazq5vPEdHtl6Ii1rR+HrLp7hcntmCsOqqwl3dubblLwS3LCJaTdt4q36kRz3nZt59cqfMi5Qy/u9o3mh+Tik24evx3QtZiKf2bqqw52k9sxmlqJ37s23nMri237CSP/havzXh28gNCvMpe9dxuY9WWiYywYTDtJ19nTKn1s2IKru7808uyv+Dk1eo+n6GSz91E8Y6Xe6nj5du49Pz/ojoZmma7ET7ZkF7JnNMEXfLLP/uOCAmwScjrdfTl1Afe3BPFiVOv5AiAMN0Vsbg5u3su6pqTGPbeocCuFwtkzLC6arN3UF0xZyo21xO3efH6mOvcDU+EAtHx//bg4Nyh4TH2ni2V0zosY1PT6ZcEdyI0iKAtMV8KCuYNq65ELbonbugUnjWXjO3XHTXFu/rGhKAvuPIeZmDcGNm1m/N/oa5lJ8q9/GxXR18JquYNr2kQtti9q5h2uqqPfFr9pMDNRSX1kcN0p4ykF6TzsupWN61Y+/p7h2JEqE6epNXcG0hdxpW9TO/b1bhjAukHiu17qm6CvwFRr+QIg9x1cmnT6swk9fvoQxD3mrQ8509aauYNrmUtvide4i+Gp7k0r6v09ZmGVjMkfbnB4CY8ckTgi82Hosx39rHaH9+xMnLhZMV2/qCqYtudW2aJ27/5gpPHzmvUmlPaq8JXGiAqG8poeNNxyNryb6DM0+wiq0dVcRPuCtDjfT1Zu6gmmba22L1rlTFmBSILlSwHvdDXTvz94SpZlERAme0EFwzrQBceHwYbl+9MYl+L5Ygfb25NK87GO6elNXMG1zrG3RT2JKhlfbjqF8RxkMKY4NBnz+MDtPrmHcS/3Dx/yikn+75lICu8s4/o73CLW2Rs+gRDBdvYtpmz4l4dwBJizuZtvAP9aCpX1GDxMaGwg2bT8UFli8nGmLnc8eHCU3KExX72LapkfRNstIx0Ge7piUdPqKzXvpPlAc1TyA8toednws+evzCqardzFtc0vROvfg5q388NFP9Vs5MBZvbp1EcMMmKrfkZnurTCCiHJgAvsrkh1l5AdPVu5i2uaVonTvAUT/4O9Oe/BLdGruT5ts7Z3HUzTtyaFUGmdZB6OTUJkh4AdPVu5i2uaOonXu4q4vjv7uJW7adS2d4YA/0mp5OXrjrTEK7dgFQvi8LNoR8Was6iijrvhAgMGlC4sQewnT1LqZt7kjo3EVkgoj8VURWi8gqEbnVDf+eiDSJyNvu69KIY74lIutFZK2IXJTNCwjtbGHrOUFmPHVLv5slpGE++6PbGP7rJYfCGp9spqcrs/u81Lxaw3H/0UFwc21Whm6V1/WgNVUZz7dLO1muL7FEn2OJPs8WXdcX1WC6mq7ZxLTNDcmU3IPAbao6HZgL3Cwi0924n6nqbPf1NIAbdxUwA7gY+E8R8UfLOFNodzfH3voO53z/Vn65bywAm4KdjF52oF+60PqNVL6f2fawmp0hwu+s4eh/eoPxC/2Ew8Wx2YAgTGUWp8tFnMJ5bOMDDuihWXOmq+maVUzb7JPQuatqs6r+zf3cDqwBGuMcMg9YoKrdqroRZ+PdUzNhbFw7u7sZcd8S7r77kzx8YChXvv2P6FsrB6QLZHDTlO6Ocoas2O0aoNQ+t5Lgrsz+Y4sou+aOyGieABVSxRBxNkUISBnV1NFN3MWaTNcMUuq6gmmbbVJqcxeRycCJwFI36BYRWSEivxKRvu1TGoGtEYdtI8qfgYjcKCLLRGRZL5mbqDD6nqX8+sQTGPbz6FOBxz+zC9UM/VN3+wlv3nboa7izk+P+q43uvZm9WQ5MyG7J4qB20E4bQxneF2S6mq4DMG2TJ9vaJkPSzl1EaoHHgK+q6n7gHuBoYDbQDNyZyolVdb6qzlHVOWVksN0rHCLc0UHZouVRo6W7l1Aw/VpnOCzUrwygvf03HgitWsvxP9+X8ZslWwQ1yAqWcCyzCUgZQAumq+kaBdO2uEjKuYtIGY5j/52q/hFAVXeqakhVw8B9HK7KNQGRXcXj3bCCILhxM+MeK0+7JFD1Ri1j5i+D8MAxu6FVazn+rjYCy+vSOke2CWuYFSxhLBMZLYcKa0HT1XTNnbWJMW0Hh6jGXzReRAR4ANirql+NCB+nqs3u568Bp6nqVSIyA/g9zs3TACwGpqrGnrkgIu3A2jSvpZAYCezOtxFJMBlnVnRktXyKqo6AjOi6C+igOH6LZDBdXTz2zBaLrtGYpKqjokUks7bMmcDngZUi8rYb9m3gahGZDSiwCfgigKquEpGHgdU4I21uTnSjAGtVdU4SthQFIrKs0K9HRM4CXgFWcvg+6NN1JRnQVVVHFcNvkSzFcC250NXFM89sMeg6GBKW3HNihMd+XK9dTzp46bfw0rWki5d+Cy9dSyRFPUPVMAzDiE6hOPf5+TYgw3jtetLBS7+Fl64lXbz0W3jpWg5REM0yhmEYRmYplJK7YRiGkUHy7txF5GJ3waL1InJ7vu1JhDu7r0VE3o0IGy4iL4jIOvd9mBsuInKXe20rROSk/FmeW4pNVzBtk8F0LR7y6tzdBYp+AVwCTMcZrjU9/lF5536cBZYiuR1YrKpTccYJ9930lwBT3deNOLN6PU+R6gqmbVxM1+Ii3yX3U4H1qrpBVXuABTgLGRUsqvoysPeI4Hk4E71w3y+PCH9QHd4A6kVkXE4MzS9FpyuYtklguhYR+XbuSS9aVOCM6ZutC+wAxrifvXJ9qeKl6zZtD+Ola/a8rvl27p5DneFHNgTJg5i23sSruubbuRf8okVJsrOv6ua+t7jhXrm+VPHSdZu2h/HSNXte13w797eAqSIyRUTKcXaEeSLPNg2GJ4Dr3M/XAY9HhF/r9sDPBfZFVAW9jFd0BdM2EtO1mFDVvL6AS4H3gQ+A/5lve5Kw9yGc9bB7cdrjbgBG4PS4rwMWAcPdtIIzuuADnIWc5uTbftPVtDVdS0NXm6FqGIbhQfLdLGMYhmFkAXPuhmEYHsScu2EYhgcx524YhuFBzLkbhmF4EHPuhmEYHsScu2EYhgcx524YhuFB/j/KWgTl6vyTCQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "secondInput = (in_label * (1 - in_mask_clothes)).transpose(0, 1)[0].long()\n",
    "\n",
    "figure = plt.figure()\n",
    "figure.add_subplot(1,3, 1).set_title('old sgm')\n",
    "plt.imshow((armlabel_map[0].permute(1,2,0).detach().cpu().numpy() + 1)/2)\n",
    "figure.add_subplot(1,3, 2).set_title('new sgm')\n",
    "plt.imshow((armlabel_map_new[0].permute(1,2,0).detach().cpu().numpy() + 1)/2)\n",
    "figure.add_subplot(1,3, 3).set_title('gt')\n",
    "plt.imshow((secondInput.permute(1,2,0).detach().cpu().numpy() + 1)/2)\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The old sgm scores: 2.000629\n",
      "The new sgm scores: 2.357079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tasin\\anaconda3\\envs\\improve\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def cross_entropy2d(input, target, weight=None, size_average=True):\n",
    "    n, c, h, w = input.size()\n",
    "    nt, ht, wt = target.size()\n",
    "\n",
    "    # Handle inconsistent size between input and target\n",
    "    if h != ht or w != wt:\n",
    "        input = F.interpolate(input, size=(ht, wt), mode=\"bilinear\", align_corners=True)\n",
    "\n",
    "    input = input.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)\n",
    "    target = target.view(-1)\n",
    "    loss = F.cross_entropy(\n",
    "        input, target, weight=weight, size_average=size_average, ignore_index=250\n",
    "    )\n",
    "\n",
    "    return loss\n",
    "\n",
    "old_sgm_score = cross_entropy2d(arm_label, secondInput)\n",
    "new_sgm_score = cross_entropy2d(arm_label_new, secondInput)\n",
    "print(\"The old sgm scores: %f\" % old_sgm_score.item())\n",
    "print(\"The new sgm scores: %f\" % new_sgm_score.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(armlabel_map_new, 'sgm.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "improve",
   "language": "python",
   "name": "improve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
